{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal code to run a LLM\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "model_name = '/home/xxh584/data/hf_models/Meta-Llama-3.1-8B-Instruct'\n",
    "# model_name = '/home/xxh584/data/hf_models/Llama-3.2-1B'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, config=config, attn_implementation = \"flash_attention_2\", torch_dtype=torch.bfloat16).cuda()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "input_text = \"What is the capital of France? The answer is: \"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "input_ids = input_ids.cuda()\n",
    "\n",
    "# Run the model\n",
    "tokens = model.generate(input_ids, max_new_tokens=20, use_cache=True)\n",
    "output_text = tokenizer.decode(tokens[0][len(input_ids[0]):], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we quantify language quality?\n",
    "\n",
    "N-Grams\n",
    "- contiguous sequence of 'n' items from a given sample of text or speech\n",
    "- Challenges: storage limitations, less likely to find repeated instances of the same sequence (sparsity), lack of semantic understanding\n",
    "\n",
    "BLEU score \n",
    "- way to use n-grams to measure \"precision\"\n",
    "- For each value of \"n-gram\" length, precision is calcualted as the ratio of the number of overlapping n-grams to the total number of n-grams in the candidate translation\n",
    "- Brevity Penalty\n",
    "  - To penalize the model for being too brief\n",
    "\n",
    "ROUGE score\n",
    "- measures overlap of n-grams between the generated text and the reference text\n",
    "- ROUGE-N = (Number of overlapping n-grams) / (Total n-grams in the reference text)\n",
    "\n",
    "BLEU vs. ROUGE\n",
    "- precision vs. recall\n",
    "- BLEU measures how many n-grams in the generated text match the reference text, but it doesn't consider if the reference text contains additional important information that's missing in the generated text\n",
    "- ROUGE is more recall-oreiented. It measures how much of the reference text is captured by the generated text. It is more forgiving of shorter generated texts and useful for summarization tasks where it's crucial that the generated text includes key information\n",
    "\n",
    "To address the limitations of traditional NLP eval:\n",
    "- BERTScore and word vectors (semantics)\n",
    "\n",
    "![BERT Image](/Users/efang/Desktop/coding/Intro-to-ML/CSDS600/info/bert.png)\n",
    "\n",
    "BERT handles tokens, so it handles spelling mistakes and little errors. However, BERT still has issues because it takes the max similarity score out of the entire matrix between the reference and candidates. This means that semantics will still not be represented well.\n",
    "\n",
    "ex: I hate playing sports and have never wanted to visit the Olympics.\n",
    "I love playing sports and have always wanted to visit the Olympics.\n",
    "\n",
    "Problems of BERTScore and its descendatns\n",
    "- Maximum cosine similarity values are selected as representational values\n",
    "- \"differences\" will be under-represented, unless they are catastrophically different\n",
    "\n",
    "BLEURT\n",
    "- built using multiple phases of transfer learning starting from pretrained BERT model\n",
    "- regression model trained on ratings data, which means that everything that differs from training data could make the results different\n",
    "\n",
    "T5\n",
    "- Text-To-Text Transfer transformer, treats every task as a text generation problem\n",
    "\n",
    "Datasets and Correlation studies\n",
    "- Everyone has already done correlation before (BERTScore, BLEURT, etc.)\n",
    "- Datasets are as close to Gold standard as you can get at scale, Rajpulakar et al 2018\n",
    "- SQuAD dataset (Stanford Question Answering dataset)\n",
    "  - performance is judged by \"exact match\" of n-grams between actual answer and predicted\n",
    "- Translation: WMT dataset (Tran et al 2021)\n",
    "  - contains several translation pairs, widely trained/tested for translation task\n",
    "  - Translation largely suffers from same issues as does semantic similarity prediction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Safety and Responsible AI\n",
    "\n",
    "How do we measure safety in LLMs?\n",
    "- Langage models predict the next token in a sequence\n",
    "- Can we see if there is a bias in the distribution of tokens?\n",
    "\n",
    "![LLM Safety Image](/Users/efang/Desktop/coding/Intro-to-ML/CSDS600/info/llmsafety.png)\n",
    "\n",
    "As seen in the equation, we are looking at the distribution of female given context, over males given context. This is a measurement of gender bias.\n",
    "- In one experiment, this measurement returned -2.14 for the \"competent\" variant, and -1.14 for \"incompentent\" variant, and -1.1 for neutral variant.\n",
    "- There was a lot of bias towards males, saying that \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning\n",
    "\n",
    "### What is Chain of Thought? (CoT)\n",
    "- Series of intermediate reasoning steps, like walking yourself through logical reasoning through a question\n",
    "\n",
    "### But what is reasoning?\n",
    "- Reasoning is the cognitive proces of drawing conclusions, making decisions, and solving problems based on logical thinking, eivdence, and analysis. It involves critical thinking, as well as the use of deduction and induction, to arrive at sound judgements\n",
    "- Contextual information, which is what CoT attempts to solve in language modeling\n",
    "- CoT gives the context to LLMs, such that the probability of each generated token is conditioned on the chain of previous tokens\n",
    "\n",
    "### Bounded Rationality\n",
    "- Idea that when individuals make decisions, their rationality is limited by the information they have, the cognitive limitations of their minds, and the finite amount of time they have to make a decision.\n",
    "- <a hlink=\"https://thedecisionlab.com/biases/bounded-rationality\">link</a>\n",
    "\n",
    "### LLMs and Cognitive Biases\n",
    "- human survival\n",
    "- survivorship bias\n",
    "- bounded rationality\n",
    "- mental shortcuts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability, Robustness, and Trustworthiness\n",
    "\n",
    "## What is explainable AI?\n",
    "- Core of it is making AI understandable by people\n",
    "- Challenging because not all models are directly explainable\n",
    "- Explainability-performance tradeoff\n",
    "\n",
    "### Jailbreaking and Mitigation Strategies\n",
    "- Few shot and many shot jailbreaking\n",
    "    - Giving examples of malicious use-case examples to a LLM, and \"jailbreaking\" it to provide malicious answers to a prompt.\n",
    "\n",
    "### Standard Benchmarks\n",
    "- There exists benchmarks for LLM safety, such as SafetyBench, R-Judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
